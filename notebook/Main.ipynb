{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXQV6kQiH80L"
      },
      "source": [
        "Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9uGQrU0Hu7t",
        "outputId": "6cdaed60-01ba-494f-f47d-c8979102560f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "# Set a consistent random state for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKTP05gJIHjD"
      },
      "source": [
        "Part I: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVLqk1--IJGH",
        "outputId": "1bd9d639-fa39-4737-d52b-f7f24212edf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Part 1: Data Preprocessing ---\n",
            "Files loaded successfully.\n",
            "Data shapes before scaling: X_train: (125973, 122), X_test: (22544, 122)\n",
            "Features normalized with Min-Max scaling.\n",
            "Class distribution before SMOTE: Counter({0: 67343, 1: 58630})\n",
            "Class distribution after SMOTE: Counter({0: 67343, 1: 67343})\n",
            "--- Data Preprocessing Complete ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Part 1: Data Preprocessing ---\")\n",
        "\n",
        "# --- Step 2.1: Loading and Labeling [cite: 47] ---\n",
        "# Define the 41 feature names plus the 'attack' and 'level' columns\n",
        "column_names = [\n",
        "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
        "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
        "    'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
        "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
        "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
        "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
        "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
        "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
        "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
        "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
        "    'attack', 'level'\n",
        "]\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    # Update these paths to your file locations\n",
        "    train_df = pd.read_csv('KDDTrain+.txt', header=None, names=column_names)\n",
        "    test_df = pd.read_csv('KDDTest+.txt', header=None, names=column_names)\n",
        "    print(\"Files loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset files not found. Please check paths.\")\n",
        "    # In a real script, you might exit here.\n",
        "\n",
        "# --- Step 2.2: Binary Target Mapping [cite: 49-51] ---\n",
        "# Map 'normal' to 0 and all attack types to 1\n",
        "train_df['attack_flag'] = train_df['attack'].apply(lambda x: 0 if x == 'normal' else 1)\n",
        "test_df['attack_flag'] = test_df['attack'].apply(lambda x: 0 if x == 'normal' else 1)\n",
        "\n",
        "# Drop original text columns\n",
        "train_df = train_df.drop(columns=['attack', 'level'])\n",
        "test_df = test_df.drop(columns=['attack', 'level'])\n",
        "\n",
        "# --- Step 2.3: Categorical Feature Encoding [cite: 52-54] ---\n",
        "categorical_features = ['protocol_type', 'service', 'flag']\n",
        "combined_df = pd.concat([train_df, test_df], keys=['train', 'test'])\n",
        "\n",
        "# One-hot encode\n",
        "combined_encoded_df = pd.get_dummies(combined_df, columns=categorical_features)\n",
        "\n",
        "# Separate back into train and test\n",
        "train_df_encoded = combined_encoded_df.loc['train']\n",
        "test_df_encoded = combined_encoded_df.loc['test']\n",
        "\n",
        "# Align columns - ensures train and test have the exact same columns after encoding\n",
        "train_cols = train_df_encoded.columns.drop('attack_flag')\n",
        "test_cols = test_df_encoded.columns.drop('attack_flag')\n",
        "\n",
        "missing_in_test = set(train_cols) - set(test_cols)\n",
        "for c in missing_in_test:\n",
        "    test_df_encoded[c] = 0\n",
        "\n",
        "missing_in_train = set(test_cols) - set(train_cols)\n",
        "for c in missing_in_train:\n",
        "    train_df_encoded[c] = 0\n",
        "\n",
        "test_df_encoded = test_df_encoded[train_df_encoded.columns]\n",
        "test_df_encoded = test_df_encoded.reindex(columns=train_df_encoded.columns, fill_value=0)\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X_train = train_df_encoded.drop(columns='attack_flag')\n",
        "y_train = train_df_encoded['attack_flag']\n",
        "X_test = test_df_encoded.drop(columns='attack_flag')\n",
        "y_test = test_df_encoded['attack_flag']\n",
        "\n",
        "# Ensure column order is identical\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "print(f\"Data shapes before scaling: X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "\n",
        "# --- Step 2.4: Feature Space Normalization [cite: 55-59] ---\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame to keep column names\n",
        "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "print(\"Features normalized with Min-Max scaling.\")\n",
        "\n",
        "# --- Step 2.5: Class Imbalance Mitigation (SMOTE) [cite: 60-64] ---\n",
        "print(f\"Class distribution before SMOTE: {Counter(y_train)}\")\n",
        "smote = SMOTE(random_state=RANDOM_STATE)\n",
        "# Apply SMOTE ONLY to training data\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "print(f\"Class distribution after SMOTE: {Counter(y_train_smote)}\")\n",
        "\n",
        "print(\"--- Data Preprocessing Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc6TxtELJIqY"
      },
      "source": [
        "Part II: Model & Attack Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifoxqj2MJPf7",
        "outputId": "5d33724d-5d43-41ed-9769-d508afa65d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Part 2: Model & Attack Definitions ---\n",
            "Model input dimensions set to: 122\n",
            "Defined: PyTorchLogisticRegression class, fgsm_attack function\n",
            "Defined: pgd_attack function\n",
            "Defined: get_pytorch_probs helper\n",
            "--- Model & Attack Definitions Complete ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Part 2: Model & Attack Definitions ---\")\n",
        "\n",
        "# --- Model Architecture: PyTorch Logistic Regression ---\n",
        "# This architecture is used for all robust models [cite: 88, 153]\n",
        "class PyTorchLogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(PyTorchLogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Returns raw logits, not probabilities\n",
        "        return self.linear(x)\n",
        "\n",
        "# Get input dimension from our data\n",
        "input_dim = X_train_smote.shape[1]\n",
        "print(f\"Model input dimensions set to: {input_dim}\")\n",
        "\n",
        "# --- Attack Function 1: FGSM [cite: 74-80] ---\n",
        "def fgsm_attack(model, loss_function, x, y, epsilon):\n",
        "    \"\"\"Generates adversarial examples using FGSM.\"\"\"\n",
        "    x.requires_grad = True\n",
        "\n",
        "    outputs = model(x)\n",
        "    loss = loss_function(outputs, y)\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    data_grad = x.grad.data\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    x_adv = x + epsilon * sign_data_grad\n",
        "\n",
        "    # Clip to valid [0, 1] range [cite: 116]\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "\n",
        "    return x_adv.detach()\n",
        "\n",
        "print(\"Defined: PyTorchLogisticRegression class, fgsm_attack function\")\n",
        "\n",
        "# --- Attack Function 2: PGD [cite: 160-186] ---\n",
        "def pgd_attack(model, loss_function, x, y, epsilon, alpha, num_iter):\n",
        "    \"\"\"Generates adversarial examples using PGD.\"\"\"\n",
        "    # Start with a random perturbation\n",
        "    x_adv = x.clone().detach() + torch.empty_like(x).uniform_(-epsilon, epsilon)\n",
        "    x_adv = torch.clamp(x_adv, 0, 1) # Ensure valid start\n",
        "\n",
        "    x_clean = x.clone().detach()\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        x_adv.requires_grad = True\n",
        "\n",
        "        outputs = model(x_adv)\n",
        "        loss = loss_function(outputs, y)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Take a small step\n",
        "        x_adv = x_adv.detach() + alpha * x_adv.grad.sign()\n",
        "\n",
        "        # Project perturbation back into epsilon-ball\n",
        "        perturbation = torch.clamp(x_adv - x_clean, min=-epsilon, max=epsilon)\n",
        "        x_adv = x_clean + perturbation\n",
        "\n",
        "        # Clip to valid [0, 1] range\n",
        "        x_adv = torch.clamp(x_adv, 0, 1)\n",
        "\n",
        "    return x_adv.detach()\n",
        "\n",
        "print(\"Defined: pgd_attack function\")\n",
        "\n",
        "# --- Helper for Weighted Averaging ---\n",
        "def get_pytorch_probs(model, X_tensor):\n",
        "    \"\"\"Helper function to get [prob_0, prob_1] from a PyTorch model.\"\"\"\n",
        "    model.eval()\n",
        "    X_tensor = X_tensor.to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(X_tensor)\n",
        "        probs_attack = torch.sigmoid(logits) # Prob of class 1\n",
        "        probs_normal = 1 - probs_attack      # Prob of class 0\n",
        "        return torch.cat((probs_normal, probs_attack), dim=1).cpu().numpy()\n",
        "\n",
        "print(\"Defined: get_pytorch_probs helper\")\n",
        "print(\"--- Model & Attack Definitions Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH-lJPcyJaQf"
      },
      "source": [
        "Part III: Train Specialist Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nm1QoWpJbk0",
        "outputId": "2c6cf19d-4ad7-4a0e-858b-ea9a98340814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Part 3: Training Specialist Models ---\n",
            "PyTorch DataLoaders created.\n",
            "\n",
            "Training 1/3: Standard Model (Scikit-learn)...\n",
            "Standard Model trained.\n",
            "\n",
            "Training 2/3: FGSM-Robust Model (PyTorch)...\n",
            "FGSM Model - Epoch [1/10], Loss: 0.1948\n",
            "FGSM Model - Epoch [2/10], Loss: 0.2590\n",
            "FGSM Model - Epoch [3/10], Loss: 0.0605\n",
            "FGSM Model - Epoch [4/10], Loss: 0.0722\n",
            "FGSM Model - Epoch [5/10], Loss: 0.1065\n",
            "FGSM Model - Epoch [6/10], Loss: 0.1392\n",
            "FGSM Model - Epoch [7/10], Loss: 0.2069\n",
            "FGSM Model - Epoch [8/10], Loss: 0.1376\n",
            "FGSM Model - Epoch [9/10], Loss: 0.0177\n",
            "FGSM Model - Epoch [10/10], Loss: 0.2056\n",
            "FGSM-Robust Model trained.\n",
            "\n",
            "Training 3/3: PGD-Robust Model (PyTorch)...\n",
            "PGD Model - Epoch [1/10], Loss: 0.2982\n",
            "PGD Model - Epoch [2/10], Loss: 0.1362\n",
            "PGD Model - Epoch [3/10], Loss: 0.1081\n",
            "PGD Model - Epoch [4/10], Loss: 0.0896\n",
            "PGD Model - Epoch [5/10], Loss: 0.0465\n",
            "PGD Model - Epoch [6/10], Loss: 0.0611\n",
            "PGD Model - Epoch [7/10], Loss: 0.2189\n",
            "PGD Model - Epoch [8/10], Loss: 0.1127\n",
            "PGD Model - Epoch [9/10], Loss: 0.2196\n",
            "PGD Model - Epoch [10/10], Loss: 0.0809\n",
            "PGD-Robust Model trained.\n",
            "--- All Specialist Models Trained ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Part 3: Training Specialist Models ---\")\n",
        "\n",
        "# --- Common Hyperparameters ---\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001\n",
        "ALPHA_LOSS = 0.5 # Balances clean vs. adversarial loss [cite: 95-97]\n",
        "\n",
        "# FGSM Attack Hyperparameters\n",
        "EPSILON_FGSM = 0.05\n",
        "\n",
        "# PGD Attack Hyperparameters\n",
        "EPSILON_PGD = 0.05\n",
        "ALPHA_PGD = 0.01\n",
        "NUM_ITER_PGD = 7\n",
        "\n",
        "# --- Convert data to PyTorch Tensors and create DataLoaders ---\n",
        "# Training Data (SMOTE)\n",
        "X_train_tensor = torch.tensor(X_train_smote.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_smote.values, dtype=torch.float32).view(-1, 1)\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Test Data (Clean, original)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
        "# Note: y_test_numpy is used for scikit-learn metrics later\n",
        "y_test_numpy = y_test.values\n",
        "\n",
        "print(\"PyTorch DataLoaders created.\")\n",
        "\n",
        "# --- 4.1: Standard Model (Accuracy Specialist) [cite: 6-40] ---\n",
        "print(\"\\nTraining 1/3: Standard Model (Scikit-learn)...\")\n",
        "standard_model = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
        "standard_model.fit(X_train_smote, y_train_smote)\n",
        "print(\"Standard Model trained.\")\n",
        "\n",
        "# --- 4.2: FGSM-Robust Model (Baseline Robustness) [cite: 66-124] ---\n",
        "print(\"\\nTraining 2/3: FGSM-Robust Model (PyTorch)...\")\n",
        "fgsm_robust_model = PyTorchLogisticRegression(input_dim).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(fgsm_robust_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "fgsm_robust_model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        # 1. Attacker's Move: Generate FGSM examples\n",
        "        batch_x_adv = fgsm_attack(fgsm_robust_model, criterion, batch_x, batch_y, EPSILON_FGSM)\n",
        "\n",
        "        # 2. Defender's Countermove: Train on combined loss\n",
        "        outputs_clean = fgsm_robust_model(batch_x)\n",
        "        outputs_adv = fgsm_robust_model(batch_x_adv)\n",
        "\n",
        "        loss_clean = criterion(outputs_clean, batch_y)\n",
        "        loss_adv = criterion(outputs_adv, batch_y)\n",
        "        loss = (ALPHA_LOSS * loss_clean) + ((1 - ALPHA_LOSS) * loss_adv)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"FGSM Model - Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {loss.item():.4f}\")\n",
        "print(\"FGSM-Robust Model trained.\")\n",
        "\n",
        "# --- 4.3: PGD-Robust Model (Robustness Specialist) [cite: 127-189] ---\n",
        "print(\"\\nTraining 3/3: PGD-Robust Model (PyTorch)...\")\n",
        "pgd_robust_model = PyTorchLogisticRegression(input_dim).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(pgd_robust_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "pgd_robust_model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        # 1. Attacker's Move: Generate PGD examples\n",
        "        batch_x_adv = pgd_attack(\n",
        "            pgd_robust_model, criterion, batch_x, batch_y,\n",
        "            EPSILON_PGD, ALPHA_PGD, NUM_ITER_PGD\n",
        "        )\n",
        "\n",
        "        # 2. Defender's Countermove: Train on combined loss\n",
        "        outputs_clean = pgd_robust_model(batch_x)\n",
        "        outputs_adv = pgd_robust_model(batch_x_adv)\n",
        "\n",
        "        loss_clean = criterion(outputs_clean, batch_y)\n",
        "        loss_adv = criterion(outputs_adv, batch_y)\n",
        "        loss = (ALPHA_LOSS * loss_clean) + ((1 - ALPHA_LOSS) * loss_adv)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"PGD Model - Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {loss.item():.4f}\")\n",
        "print(\"PGD-Robust Model trained.\")\n",
        "print(\"--- All Specialist Models Trained ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjMzS8DdJjdf"
      },
      "source": [
        "Part IV: Evaluation Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7viMNGlJoYv",
        "outputId": "4519377d-f356-46f7-b3fc-361184aa51fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Part 4: Evaluation Framework ---\n",
            "Training naive PyTorch model (for attack generation)...\n",
            "Naive gradient source model trained.\n",
            "Generating adversarial testbeds...\n",
            "1. Clean Test Set loaded.\n",
            "2. FGSM Adversarial Test Set generated.\n",
            "3. PGD Adversarial Test Set generated.\n",
            "All testbeds are ready.\n",
            "Evaluation helper functions defined.\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Part 4: Evaluation Framework ---\")\n",
        "\n",
        "# --- 5.1: Create Attack Gradient Source Model ---\n",
        "# This is a 'naive' model trained only on clean data\n",
        "# Its gradients are used to create the adversarial test sets [cite: 264, 271]\n",
        "print(\"Training naive PyTorch model (for attack generation)...\")\n",
        "naive_pytorch_model = PyTorchLogisticRegression(input_dim).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(naive_pytorch_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "naive_pytorch_model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        outputs = naive_pytorch_model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "print(\"Naive gradient source model trained.\")\n",
        "\n",
        "# --- 5.2: Generate Adversarial Testbeds  ---\n",
        "print(\"Generating adversarial testbeds...\")\n",
        "naive_pytorch_model.eval()\n",
        "\n",
        "# 1. Clean Test Set (already have X_test_tensor, X_test)\n",
        "X_test_clean_tensor = X_test_tensor.to(device)\n",
        "X_test_clean_numpy = X_test.values\n",
        "print(\"1. Clean Test Set loaded.\")\n",
        "\n",
        "# 2. FGSM Adversarial Test Set\n",
        "X_test_fgsm_tensor = fgsm_attack(\n",
        "    naive_pytorch_model, criterion, X_test_clean_tensor, y_test_tensor.to(device), EPSILON_FGSM\n",
        ").to(device)\n",
        "X_test_fgsm_numpy = X_test_fgsm_tensor.cpu().detach().numpy()\n",
        "print(\"2. FGSM Adversarial Test Set generated.\")\n",
        "\n",
        "# 3. PGD Adversarial Test Set\n",
        "X_test_pgd_tensor = pgd_attack(\n",
        "    naive_pytorch_model, criterion, X_test_clean_tensor, y_test_tensor.to(device),\n",
        "    EPSILON_PGD, ALPHA_PGD, NUM_ITER_PGD\n",
        ").to(device)\n",
        "X_test_pgd_numpy = X_test_pgd_tensor.cpu().detach().numpy()\n",
        "print(\"3. PGD Adversarial Test Set generated.\")\n",
        "print(\"All testbeds are ready.\")\n",
        "\n",
        "\n",
        "# --- 5.3: Define Evaluation Helper Functions ---\n",
        "def evaluate_sklearn_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    return {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred, zero_division=0)\n",
        "    }\n",
        "\n",
        "def evaluate_pytorch_model(model, X_tensor, y_test):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_logits = model(X_tensor)\n",
        "        y_probs = torch.sigmoid(y_logits)\n",
        "        y_pred = (y_probs > 0.5).float().cpu().numpy()\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred, zero_division=0)\n",
        "    }\n",
        "\n",
        "print(\"Evaluation helper functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNyGML14lDT2"
      },
      "source": [
        "Final Analysis & Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6RRH4RElFGa",
        "outputId": "204ff76f-6c13-461b-9b6d-61a97a807aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Part 5: Final Analysis ---\n",
            "Executing 4x3 Evaluation Matrix...\n",
            "Evaluating 1/4: Standard Model\n",
            "Evaluating 2/4: FGSM-Robust Model\n",
            "Evaluating 3/4: PGD-Robust Model\n",
            "Evaluating 4/4: Hybrid (Defensive Avg.) Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\manid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\manid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\manid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\manid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\manid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\manid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation complete.\n",
            "\n",
            "\n",
            "--- FINAL COMPREHENSIVE RESULTS [cite: 293-298] ---\n",
            "|                                |   Accuracy |   Precision |   Recall |   F1-Score |\n",
            "|:-------------------------------|-----------:|------------:|---------:|-----------:|\n",
            "| ('Standard', 'Clean')          |     0.7547 |      0.9169 |   0.6258 |     0.7439 |\n",
            "| ('Standard', 'FGSM Adv.')      |     0.3201 |      0.4122 |   0.4562 |     0.4331 |\n",
            "| ('Standard', 'PGD Adv.')       |     0.3267 |      0.4170 |   0.4594 |     0.4372 |\n",
            "| ('FGSM Adv.', 'Clean')         |     0.7382 |      0.9148 |   0.5955 |     0.7214 |\n",
            "| ('FGSM Adv.', 'FGSM Adv.')     |     0.7045 |      0.8943 |   0.5453 |     0.6775 |\n",
            "| ('FGSM Adv.', 'PGD Adv.')      |     0.7055 |      0.8948 |   0.5469 |     0.6789 |\n",
            "| ('PGD Adv.', 'Clean')          |     0.7390 |      0.9147 |   0.5972 |     0.7226 |\n",
            "| ('PGD Adv.', 'FGSM Adv.')      |     0.7066 |      0.8940 |   0.5497 |     0.6808 |\n",
            "| ('PGD Adv.', 'PGD Adv.')       |     0.7081 |      0.8949 |   0.5520 |     0.6828 |\n",
            "| ('Hybrid (Avg.)', 'Clean')     |     0.7385 |      0.9143 |   0.5966 |     0.7220 |\n",
            "| ('Hybrid (Avg.)', 'FGSM Adv.') |     0.6891 |      0.8832 |   0.5230 |     0.6570 |\n",
            "| ('Hybrid (Avg.)', 'PGD Adv.')  |     0.6898 |      0.8838 |   0.5239 |     0.6578 |\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Part 5: Final Analysis ---\")\n",
        "print(\"Executing 4x3 Evaluation Matrix...\")\n",
        "\n",
        "all_results = []\n",
        "testbeds_sklearn = {\n",
        "    \"Clean\": X_test_clean_numpy,\n",
        "    \"FGSM Adv.\": X_test_fgsm_numpy,\n",
        "    \"PGD Adv.\": X_test_pgd_numpy\n",
        "}\n",
        "testbeds_pytorch = {\n",
        "    \"Clean\": X_test_clean_tensor,\n",
        "    \"FGSM Adv.\": X_test_fgsm_tensor,\n",
        "    \"PGD Adv.\": X_test_pgd_tensor\n",
        "}\n",
        "\n",
        "# --- 1. Evaluate Standard Model ---\n",
        "print(\"Evaluating 1/4: Standard Model\")\n",
        "for name, X in testbeds_sklearn.items():\n",
        "    metrics = evaluate_sklearn_model(standard_model, X, y_test_numpy)\n",
        "    all_results.append({\"Model\": \"Standard\", \"Test Set\": name, **metrics})\n",
        "\n",
        "# --- 2. Evaluate FGSM-Robust Model ---\n",
        "print(\"Evaluating 2/4: FGSM-Robust Model\")\n",
        "for name, X in testbeds_pytorch.items():\n",
        "    metrics = evaluate_pytorch_model(fgsm_robust_model, X, y_test_numpy)\n",
        "    all_results.append({\"Model\": \"FGSM Adv.\", \"Test Set\": name, **metrics})\n",
        "\n",
        "# --- 3. Evaluate PGD-Robust Model ---\n",
        "print(\"Evaluating 3/4: PGD-Robust Model\")\n",
        "for name, X in testbeds_pytorch.items():\n",
        "    metrics = evaluate_pytorch_model(pgd_robust_model, X, y_test_numpy)\n",
        "    all_results.append({\"Model\": \"PGD Adv.\", \"Test Set\": name, **metrics})\n",
        "\n",
        "# --- 4. Evaluate Hybrid Model (Defensive Weighted Average) ---\n",
        "print(\"Evaluating 4/4: Hybrid (Defensive Avg.) Model\")\n",
        "weights = {'std': 0.2, 'fgsm': 0.3, 'pgd': 0.5}\n",
        "\n",
        "for name in testbeds_sklearn.keys():\n",
        "    # Get probs from all 3 models for this testbed\n",
        "    probs_std = standard_model.predict_proba(testbeds_sklearn[name])\n",
        "    probs_fgsm = get_pytorch_probs(fgsm_robust_model, testbeds_pytorch[name])\n",
        "    probs_pgd = get_pytorch_probs(pgd_robust_model, testbeds_pytorch[name])\n",
        "\n",
        "    # Apply the weighted average\n",
        "    final_probs = (\n",
        "        (weights['std'] * probs_std) +\n",
        "        (weights['fgsm'] * probs_fgsm) +\n",
        "        (weights['pgd'] * probs_pgd)\n",
        "    )\n",
        "    final_preds = np.argmax(final_probs, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test_numpy, final_preds),\n",
        "        \"Precision\": precision_score(y_test_numpy, final_preds, zero_division=0),\n",
        "        \"Recall\": recall_score(y_test_numpy, final_preds, zero_division=0),\n",
        "        \"F1-Score\": f1_score(y_test_numpy, final_preds, zero_division=0)\n",
        "    }\n",
        "    all_results.append({\"Model\": \"Hybrid (Avg.)\", \"Test Set\": name, **metrics})\n",
        "\n",
        "print(\"Evaluation complete.\")\n",
        "\n",
        "# --- Present the Final Table ---\n",
        "results_df = pd.DataFrame(all_results)\n",
        "final_table = results_df.set_index([\"Model\", \"Test Set\"])\n",
        "\n",
        "pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "print(\"\\n\\n--- FINAL COMPREHENSIVE RESULTS [cite: 293-298] ---\")\n",
        "print(final_table.to_markdown(floatfmt=\".4f\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 4x3 Payoff Matrix (Defender's Accuracy) ---\n",
            "| Model         |   Clean |   FGSM Adv. |   PGD Adv. |\n",
            "|:--------------|--------:|------------:|-----------:|\n",
            "| FGSM Adv.     |  0.7382 |      0.7045 |     0.7055 |\n",
            "| Hybrid (Avg.) |  0.7385 |      0.6891 |     0.6898 |\n",
            "| PGD Adv.      |  0.7390 |      0.7066 |     0.7081 |\n",
            "| Standard      |  0.7547 |      0.3201 |     0.3267 |\n",
            "\n",
            "\n",
            "--- Defender's (Our) Analysis (Maximin) ---\n",
            "Model: FGSM Adv.       | Worst-Case Accuracy (Row Min): 0.7045\n",
            "Model: Hybrid (Avg.)   | Worst-Case Accuracy (Row Min): 0.6891\n",
            "Model: PGD Adv.        | Worst-Case Accuracy (Row Min): 0.7066\n",
            "Model: Standard        | Worst-Case Accuracy (Row Min): 0.3201\n",
            "\n",
            "Best 'Worst-Case' (Maximin): 0.7066\n",
            "Optimal Defender Strategy (Maximin): Deploy 'PGD Adv.'\n",
            "\n",
            "--- Attacker's Analysis (Minimax) ---\n",
            "Attack: Clean      | Worst-Case for Attacker (Col Max): 0.7547\n",
            "Attack: FGSM Adv.  | Worst-Case for Attacker (Col Max): 0.7066\n",
            "Attack: PGD Adv.   | Worst-Case for Attacker (Col Max): 0.7081\n",
            "\n",
            "Attacker's Best 'Worst-Case' (Minimax): 0.7066\n",
            "\n",
            "--- Nash Equilibrium Analysis ---\n",
            "Game Type: Pure Strategy (Saddle Point) Exists!\n",
            "  - Defender's Best Strategy: Always play 'PGD Adv.'\n",
            "  - Attacker's Best Strategy: Always play 'FGSM Adv.'\n",
            "  - Value of the Game: 0.7066\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def analyze_game_matrix(payoff_matrix_df):\n",
        "    \"\"\"\n",
        "    Analyzes a payoff matrix (as a DataFrame) to find the maximin strategy\n",
        "    and check for a pure strategy (saddle point).\n",
        "    \n",
        "    Args:\n",
        "    payoff_matrix_df (pd.DataFrame): DataFrame where rows are defender strategies\n",
        "                                     (models) and columns are attacker strategies\n",
        "                                     (test sets). Values are defender's payoff\n",
        "                                     (accuracy).\n",
        "    \"\"\"\n",
        "    \n",
        "    payoff_matrix = payoff_matrix_df.values\n",
        "    model_names = payoff_matrix_df.index\n",
        "    attack_names = payoff_matrix_df.columns\n",
        "\n",
        "    print(\"--- 4x3 Payoff Matrix (Defender's Accuracy) ---\")\n",
        "    print(payoff_matrix_df.to_markdown(floatfmt=\".4f\"))\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    # 1. Find Defender's worst-case for each strategy (row minimums)\n",
        "    row_mins = np.min(payoff_matrix, axis=1)\n",
        "    \n",
        "    # 2. Find Defender's best \"worst-case\" (maximin)\n",
        "    maximin = np.max(row_mins)\n",
        "    maximin_model_index = np.argmax(row_mins)\n",
        "    maximin_model_name = model_names[maximin_model_index]\n",
        "    \n",
        "    print(\"--- Defender's (Our) Analysis (Maximin) ---\")\n",
        "    for i, model in enumerate(model_names):\n",
        "        print(f\"Model: {model:<15} | Worst-Case Accuracy (Row Min): {row_mins[i]:.4f}\")\n",
        "    \n",
        "    print(f\"\\nBest 'Worst-Case' (Maximin): {maximin:.4f}\")\n",
        "    print(f\"Optimal Defender Strategy (Maximin): Deploy '{maximin_model_name}'\")\n",
        "\n",
        "    # 3. Find Attacker's worst-case for each strategy (column maximums)\n",
        "    # (Attacker wants to minimize our accuracy, so their \"worst\" case is the\n",
        "    # highest accuracy they can be forced to allow)\n",
        "    col_maxs = np.max(payoff_matrix, axis=0)\n",
        "    \n",
        "    # 4. Find Attacker's best \"worst-case\" (minimax)\n",
        "    minimax = np.min(col_maxs)\n",
        "    minimax_attack_index = np.argmin(col_maxs)\n",
        "    minimax_attack_name = attack_names[minimax_attack_index]\n",
        "    \n",
        "    print(\"\\n--- Attacker's Analysis (Minimax) ---\")\n",
        "    for i, attack in enumerate(attack_names):\n",
        "        print(f\"Attack: {attack:<10} | Worst-Case for Attacker (Col Max): {col_maxs[i]:.4f}\")\n",
        "    \n",
        "    print(f\"\\nAttacker's Best 'Worst-Case' (Minimax): {minimax:.4f}\")\n",
        "    \n",
        "    # 5. Check for Pure Strategy (Saddle Point)\n",
        "    print(\"\\n--- Nash Equilibrium Analysis ---\")\n",
        "    if maximin == minimax:\n",
        "        print(f\"Game Type: Pure Strategy (Saddle Point) Exists!\")\n",
        "        print(f\"  - Defender's Best Strategy: Always play '{maximin_model_name}'\")\n",
        "        print(f\"  - Attacker's Best Strategy: Always play '{minimax_attack_name}'\")\n",
        "        print(f\"  - Value of the Game: {maximin:.4f}\")\n",
        "    else:\n",
        "        print(f\"Game Type: No Pure Strategy (Saddle Point).\")\n",
        "        print(\"This means a mixed strategy (using models with different probabilities) might be optimal.\")\n",
        "        print(f\"However, the most robust (Maximin) strategy is still to deploy '{maximin_model_name}'\")\n",
        "        print(f\"as it guarantees you a minimum accuracy of {maximin:.4f} no matter what the attacker does.\")\n",
        "\n",
        "# --- Main execution ---\n",
        "# This code assumes 'final_table' (a DataFrame) was created in the cell above.\n",
        "try:\n",
        "    # 'final_table' has a MultiIndex (Model, Test Set).\n",
        "    # We unstack it to create the 4x3 payoff matrix, using Accuracy.\n",
        "    payoff_df = final_table['Accuracy'].unstack()\n",
        "    \n",
        "    # Ensure the columns are in the correct logical order\n",
        "    payoff_df = payoff_df[['Clean', 'FGSM Adv.', 'PGD Adv.']]\n",
        "    \n",
        "    analyze_game_matrix(payoff_df)\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\"Error: Could not find the 'final_table' DataFrame.\")\n",
        "    print(f\"Details: {e}\")\n",
        "    print(\"Please make sure you have run the previous cell (cell 11) successfully.\")\n",
        "except KeyError:\n",
        "    print(\"Error: The 'final_table' DataFrame is missing 'Accuracy' or the expected Test Set names.\")\n",
        "    print(\"Please check the results from the previous cell.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
